{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PennNGG/Quantitative-Neuroscience/blob/master/Answers%20to%20Exercises/Python/Confidence%20Intervals%20and%20Bootstrapping%20Exercise%20Answers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkVu6eGKIIiQ"
   },
   "source": [
    "# Getting Started with Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxusMZ-UN_6m"
   },
   "source": [
    "Matlab code is found in the [NGG Statistics GitHub Repository](https://github.com/PennNGG/Statistics.git) under \"Concepts/ConfidenceIntervals.m\".\n",
    "\n",
    "\n",
    "Python code is included below. First run the code cell just below to make sure all of the required Python modules are loaded, then you can run the other cell(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1632145894820,
     "user": {
      "displayName": "Joshua Gold",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhY1fK-mWt81XFeafwTBs66lN9JXee76x713d4Y=s64",
      "userId": "06476168460066594437"
     },
     "user_tz": 240
    },
    "id": "W633IbbRIdwa"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isP38xJSbJuA"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fys3uL-UbaYR"
   },
   "source": [
    "Compute confidence/credible intervals based on the four methods described [here](https://github.com/PennNGG/Quantitative-Neuroscience/blob/master/Concepts/Python/Confidence%20Intervals%20and%20Bootstrapping.ipynb) for simulated data sampled from a population that is Gaussian distributed with mean $\\mu$=10 and standard deviation $\\sigma$=2, for *n*=5, 10, 20, 40, 80, 160, 1000 at a 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1632146051487,
     "user": {
      "displayName": "Joshua Gold",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhY1fK-mWt81XFeafwTBs66lN9JXee76x713d4Y=s64",
      "userId": "06476168460066594437"
     },
     "user_tz": 240
    },
    "id": "f7v0i-olmSJW",
    "outputId": "f2b991c1-5140-42ad-9412-a905bc3aba6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5, mean = 7.57\n",
      "1a: CI=[5.81, 9.32]\n",
      "1b: CI=[6.48, 8.65]\n",
      "2 : CI=[6.02, 9.11]\n",
      "3 : CI=[6.53, 8.60]\n",
      "----\n",
      "n = 10, mean = 10.04\n",
      "1a: CI=[8.80, 11.28]\n",
      "1b: CI=[9.22, 10.87]\n",
      "2 : CI=[9.09, 10.99]\n",
      "3 : CI=[9.21, 10.81]\n",
      "----\n",
      "n = 20, mean = 9.84\n",
      "1a: CI=[8.96, 10.72]\n",
      "1b: CI=[8.85, 10.83]\n",
      "2 : CI=[8.79, 10.89]\n",
      "3 : CI=[8.83, 10.77]\n",
      "----\n",
      "n = 40, mean = 9.85\n",
      "1a: CI=[9.23, 10.47]\n",
      "1b: CI=[9.23, 10.47]\n",
      "2 : CI=[9.21, 10.49]\n",
      "3 : CI=[9.23, 10.44]\n",
      "----\n",
      "n = 80, mean = 10.01\n",
      "1a: CI=[9.57, 10.45]\n",
      "1b: CI=[9.58, 10.45]\n",
      "2 : CI=[9.57, 10.45]\n",
      "3 : CI=[9.58, 10.44]\n",
      "----\n",
      "n = 160, mean = 10.08\n",
      "1a: CI=[9.77, 10.39]\n",
      "1b: CI=[9.79, 10.38]\n",
      "2 : CI=[9.78, 10.38]\n",
      "3 : CI=[9.78, 10.37]\n",
      "----\n",
      "n = 1000, mean = 9.94\n",
      "1a: CI=[9.81, 10.06]\n",
      "1b: CI=[9.81, 10.06]\n",
      "2 : CI=[9.81, 10.06]\n",
      "3 : CI=[9.81, 10.07]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Exercise: Compute confidence/credible intervals for simulated data sampled from a population that is Gaussian distributed with mean mu=10 and standard deviation sigma=2, for n=5, 10, 20, 40, 80 at a 95% confidence level.\n",
    "mu = 10\n",
    "sigma = 2\n",
    "alpha = 0.95\n",
    "num_bootstraps = 1000\n",
    "\n",
    "# Loop through the ns. Note that the different approaches converge on the same answer as n gets large\n",
    "for n in [5, 10, 20, 40, 80, 160, 1000]:\n",
    "   \n",
    "   # Simulate some data\n",
    "   samples = np.random.normal(mu, sigma, n)\n",
    "   \n",
    "   # Save the mean\n",
    "   sample_mean = np.mean(samples)\n",
    "   \n",
    "   # Show the mean, n\n",
    "   print(f'n = {n}, mean = {sample_mean:.2f}')\n",
    "   \n",
    "   # Method 1: analytic solution assuming Gaussian\n",
    "   #\n",
    "   # Get the z-score for the given confidence level (make it negative so we can subtract it to make the lower interval)\n",
    "   z = -st.norm.ppf((1-alpha)/2)\n",
    "\n",
    "   # 1a. Use the given sigma\n",
    "   sem = sigma/np.sqrt(n)\n",
    "   print(f'1a: CI=[{sample_mean-sem*z:.2f}, {sample_mean+sem*z:.2f}]')\n",
    "      \n",
    "   # 1b. Use the sample sigma\n",
    "   #     BEST IF n IS LARGE (>30)\n",
    "   sem = np.std(samples)/np.sqrt(n)\n",
    "   print(f'1b: CI=[{sample_mean-sem*z:.2f}, {sample_mean+sem*z:.2f}]')\n",
    "   \n",
    "   # Method 2: analytic solution assuming t-distribution\n",
    "   #      BEST IF n IS SMALL (<30) ... note that as n increases, the t distribution approaches a Gaussian and methods 1 and 2 become more and more similar\n",
    "\n",
    "   # Get the cutoff using the t distribution, which is said to have n-1 degrees of freedom\n",
    "   t = -st.t.ppf((1-alpha)/2,df=n-1)\n",
    "   sem = np.std(samples)/np.sqrt(n);\n",
    "   print(f'2 : CI=[{sample_mean-sem*t:.2f}, {sample_mean+sem*t:.2f}]')\n",
    "   \n",
    "   # Method 3: bootstrap!\n",
    "   # Resample the data with replacement to get new estimates of mu \n",
    "   # Note that here we do not make any assumptions about the nature of the real distribution.\n",
    "   mu_star = [np.mean(np.random.choice(samples, size=n)) for ii in np.arange(num_bootstraps)]\n",
    "   \n",
    "   # Now report the CI directly from the bootstrapped distribution\n",
    "   print(f'3 : CI=[{np.percentile(mu_star, 100*(1-alpha)/2):.2f}, {np.percentile(mu_star, 100*(alpha+(1-alpha)/2)):.2f}]')\n",
    "            \n",
    "   # Method 4: Credible interval\n",
    "   # See the Canvas discussion -- under these assumptions (i.e., data generated from a Gaussian distribution with known sigma), the answer is exactly the same as with Method 1, above. Note that this equivalence is NOT true in general, which means that frequentist confidence intervals and Bayesian credible intervals can givedifferent answers for certain distributions.\n",
    "   \n",
    "   # Formatting\n",
    "   print(f'----')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tteEm2Qlgbb3"
   },
   "source": [
    "# Credits\n",
    "\n",
    "Copyright 2021 by Joshua I. Gold, University of Pennsylvania"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bkVu6eGKIIiQ"
   ],
   "name": "Confidence Intervals and Bootstrapping",
   "provenance": [
    {
     "file_id": "1HW0L_d5Wpod3jbnY3iG7mLhMG6yWHvF2",
     "timestamp": 1626350171621
    },
    {
     "file_id": "1-KxH3FCq5rDyyO33HXxewIv-kKldkINi",
     "timestamp": 1626290714843
    },
    {
     "file_id": "14S2ca44h8TKC1hFXjk5ktwBYpGU6R5S-",
     "timestamp": 1624411796822
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
