{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Independence and Lack Thereof","provenance":[{"file_id":"1R26jZt5UmttyMWS2Aucb-wD-JSRBDYPt","timestamp":1626288328004},{"file_id":"1-KxH3FCq5rDyyO33HXxewIv-kKldkINi","timestamp":1626274090141},{"file_id":"14S2ca44h8TKC1hFXjk5ktwBYpGU6R5S-","timestamp":1624411796822}],"collapsed_sections":["pKIiY6p3GRFq","bkVu6eGKIIiQ","isP38xJSbJuA"],"toc_visible":true,"authorship_tag":"ABX9TyPCUgYLHmNaYO6CrEv6onw9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pKIiY6p3GRFq"},"source":["# Definitions"]},{"cell_type":"markdown","metadata":{"id":"x7VmLUr5GTNw"},"source":["Two events are independent if and only if the probability that they both occur is equal to the product that each occurs separately:\n","\n","[1]        $P(A\\cap B)=p(A)\\times p(B)$\n","\n","where $P(A\\cap B)$ is read as \"the probability that A and B are true.\" More generally, the relationship between two events A and B does not assume independence and is written as:\n","\n","[2]        $P(A\\cap B)=p(A|B)\\times p(B) = p(B|A)\\times p(A)$\n","\n","which follows directly from the definition of conditional probability:\n","\n","[3]        $P(A|B)=\\frac{p(A\\cap B))}{p(B)}$\n","\n","That is, the probability that A is true given that you already know that B is true is equal to the probability that both are true divided (or normalized) by the probability that B is true. So put another way, if two events A and B are independent, then $P(A|B)=P(A)$ and $P(B|A)=P(A)$.\n","\n","A closely related concept is conditional independence: are two events independent given knowledge of a third event? This concept is critical for understanding how to think about analyzing data that have been collected using repeated measurements under (nominally) identical conditions. Let's call your two measurements A and B, and let's call the set of experimental conditions C. It is often the case that you want to know the probability of obtaining A and B given C. In general, computing that probability requires knowing dependencies between each of the variables:\n","\n","[4]        $P(A,B|C)=\\frac{p(A\\cap B\\cap C)}{p(C)}=P(A|B,C)\\times P(B|C)=P(B|A,C)\\times P(A|C)$\n","\n","Which is complicated. A simplifying assumption that we often make is that A and B are conditionally independent, given C; that is, the two measurements A and B depend on C being true (by definition) but they do not further depend on each other. Put another way, we assume that the values of the measurement A has no bearing on the value of the measurement B. In this case:\n","\n","[5]        $P(A|B,C)=P(A,C)\\times P(B|C)$\n","\n","Under these conditions, we often say that the two measurements A and B are independent and identically distributed, or iid, under the conditions that you tested.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V88Vh9JkX2zj"},"source":["# Practical Considerations"]},{"cell_type":"markdown","metadata":{"id":"1b27I1gYYVES"},"source":["On a practical level, you will typically be concerned with independence in terms of your experimental observations, because most statistical tests are based on the assumptions that the multiple observations within a given sample are statistically independent. A lack of independence can occur if, for example, your sample consists of multiple experimental preparations/animals but also multiple observations within each experimental preparation/animal. In this case, there may be dependencies, or clusters, of data from each sample. There are ways of overcoming this challenge, as detailed in [this paper](https://pubmed.ncbi.nlm.nih.gov/24671065/)."]},{"cell_type":"markdown","metadata":{"id":"tteEm2Qlgbb3"},"source":["# Credits\n","\n","Copyright 2021 by Joshua I. Gold, University of Pennsylvania"]}]}