{"cells":[{"cell_type":"markdown","metadata":{"id":"pKIiY6p3GRFq"},"source":["# Definitions"]},{"cell_type":"markdown","metadata":{"id":"x7VmLUr5GTNw"},"source":["Correlation is a measure of association between measured (random) variables. The Pearson's correlation coefficient quantifies the strength of this association on a simple scale: it varies between -1 and 1. The larger the absolute value of this correlation coefficient, the tighter the correlation and more predictive it is. The smaller the absolute value, the weaker the correlation and less predictive. Positive values imply a positive correlation: as I eat more ice cream, my weight goes up. Negative values imply a negative correlation: as I eat more ice cream, my weight goes down (wouldn't that be great!). \n","\n","The Pearson's correlation coefficient is called parametric because it assumes a parametric form of the distributions of the two random variables, $X$ and $Y$; specifically, that both variables are [normally distributed](https://colab.research.google.com/drive/1-KxH3FCq5rDyyO33HXxewIv-kKldkINi?usp=sharing)."]},{"cell_type":"markdown","metadata":{"id":"IyCyVIIDH0rb"},"source":["# Computing for a population"]},{"cell_type":"markdown","metadata":{"id":"sYDtxlCZH5BC"},"source":["When you have full knowledge of the joint distribution of $ùëã$ and $Y$ (e.g., when working with an idealized model, not with real, finite data sets), the Pearson's correlation coefficient is typically denoted as $\\rho$ and computed in terms of the covariance between the two variables, normalized by the product of their individual standard deviations:\n","\n","$\\quad\\rho_{X,Y}=\\frac{cov(X,Y)}{\\sigma_x\\sigma_y}$\n","\n","where\n","\n","$\\quad cov(X,Y)=E\\left [ (X-\\mu_X)(Y-\\mu_Y)\\right ]$\n","\n","in which $\\mu_X$ and $\\mu_Y$ are the means of $X$ and $Y$, respectively, and $E\\left[\\right]$ denotes expected value."]},{"cell_type":"markdown","metadata":{"id":"xDpz-ktIJGhf"},"source":["# Computing for a sample"]},{"cell_type":"markdown","metadata":{"id":"c-qA27fbJM6k"},"source":["When working with real data, you have a [sample, not a population](https://colab.research.google.com/drive/1SnVM1MPaFvMSjlDLyihgeZ25OAk-k4Nk?usp=sharing), and thus need to compute the correlation coefficient (typically denoted as *r*) using sample statistics."]},{"cell_type":"markdown","metadata":{"id":"9LJSqIDXJZ4f"},"source":["## Sample Pearson's correlation coefficient"]},{"cell_type":"markdown","metadata":{"id":"Ytr0p-0MJcld"},"source":["$\\quad r_{X,Y}=\\frac{\\sum^n_{i-1}{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sqrt{\\sum^n_{i-1}{(x_i-\\bar{x})^2}}\\sqrt{\\sum^n_{i-1}{(y_i-\\bar{y})^2}}}$\n","\n","where\n","\n","$\\quad \\bar{x}=\\frac{1}{n}\\sum^n_{i=1}{x_i,\\bar{y}}=\\frac{1}{n}\\sum^n_{i=1}{y_i}$\n","\n","are the sample means."]},{"cell_type":"markdown","metadata":{"id":"F2at-qokKj34"},"source":["## Coefficient of determination"]},{"cell_type":"markdown","metadata":{"id":"KHOpKncgKoJP"},"source":["It is possible to compute $r_{X,Y}$ not just when $X$ and $Y$ are two random variables, but also when one is a random (dependent) variable (typically $Y$) and the other is an independent or explanatory variable (typically $X$). In this case, the square of the correlation coefficient ($r^2$) quantifies the total variation in one variable ($Y$) that is explained by the regression line with respect to the other variable ($X$). This quantity is called the **coefficient of determination** and is often referred to as the fraction of explained variance"]},{"cell_type":"markdown","metadata":{"id":"dRpX2JmfLAo7"},"source":["## Standard error of the sample Pearson's correlation coefficient"]},{"cell_type":"markdown","metadata":{"id":"WAWhhqGfLDrG"},"source":["The standard error of the sample *r* is computed by assuming that r follows a [Student's t distribution](https://colab.research.google.com/drive/1Q_Du5NK71Rc1qu-byh8dy8Fs39uvR_4n?usp=sharing) with two degrees of freedom (because of the two variables):\n","\n","$\\quad s_r=\\sqrt{\\frac{1-r^2}{n-2}}$\n","\n","Note that \"standard error\" refers in general to the standard deviation of a statistical estimate, which here is *r*. It is not the same thing as the \"standard error of the mean\", which refers to the standard deviation of a statistical estimate of a mean."]},{"cell_type":"markdown","metadata":{"id":"4yGAhXVULi3C"},"source":["## Confidence intervals for the sample Pearson's correlation coefficient"]},{"cell_type":"markdown","metadata":{"id":"-YIP1v0vLla_"},"source":["This is a bit tricker to compute, because r is not normally distributed, particularly around the extreme values (e.g., around 1, the distribution cannot go higher than one but can take many values <1). We therefore need to do the following (a good explanation is [here](http://faculty.washington.edu/gloftus/P317-318/Useful_Information/r_to_z/PearsonrCIs.pdf)):\n","\n","1\\. Take the Fisher's z-transformation of r:\n","\n","$\\quad z=0.5\\times ln(\\frac{1+r}{1-r})$\n","\n","2\\. Compute its standard deviation as:\n","\n","$\\quad s_z=\\sqrt{\\frac{1}{n-3}}$\n","\n","3\\. Compute confidence intervals in this z-space as we have shown [here](https://colab.research.google.com/drive/1rdJMusMZDTaM9OGsyt27tCVkSasmRj2O?usp=sharing), as: \n","\n","$\\quad z \\pm (z\\:criterion) \\times s_z$\n","\n","where the *z* criterion is determined from the desired confidence value using a [z-score calculator](http://www.z-table.com) or [norminv](https://www.mathworks.com/help/stats/norminv.html) in Matlab.\n","\n","4\\. Then translate each *z* value back to *r* as:\n","\n","$\\quad r=\\frac{e^{2z}-1}{e^{2z}-1}$\n"]},{"cell_type":"markdown","metadata":{"id":"ELEb_vqYQGdK"},"source":["## Hypothesis testing on the sample Pearson's correlation coefficient"]},{"cell_type":"markdown","metadata":{"id":"5VSSh3pMQIJf"},"source":["For $H_0: r=0$. Here we are considering a null distribution that is centered at *r*=0. In this case, we know that the distribution of *r* around that mean is symmetric, and the sample mean follows follows a [Student's *t* distribution](https://colab.research.google.com/drive/1Q_Du5NK71Rc1qu-byh8dy8Fs39uvR_4n?usp=sharing).  Therefore, our test statistic is simply the *t* statistic, which we compute as the residual (with respect to zero) of *r* divided by its standard error:\n","\n","$\\quad t=\\frac{r}{s_r}$\n","\n","with $n-2$ degrees of freedom.\n","\n","For $H_0: r=r_s,\\:where\\:r_s\\ne 0$. Here we are considering null distributions that are not centered at $r=0$ and therefore are not symmetric and do not follow a *t* distribution. We therefore first compute the *z* transformation of $r$ and $r_s$, as above. Now our test statistic is:\n","\n","$\\quad \\lambda =\\frac{z_r-z_{rs}}{\\sqrt{\\frac{1}{n-3}}}$\n","\n","with $n-2$ degrees of freedom.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nvmWeSSHSF95"},"source":["# Exercises"]},{"cell_type":"markdown","metadata":{"id":"bki88QRVSaj8"},"source":["Let's examine the relationship between these two measured variables:\n","\n","Wing length | Tail length\n","--- | ---\n","10.4 | 7.4\n","10.8 | 7.6\n","11.1 | 7.9\n","10.2 | 7.2\n","10.3 | 7.4\n","10.2 | 7.1\n","10.7 | 7.4\n","10.5 | 7.2\n","10.8 | 7.8\n","11.2 | 7.7\n","10.6 | 7.8\n","11.4 | 8.3\n","\n","Assume Wing length is the $X$ variable and Tail Length is the $Y$ variable, both measured in cm.\n","\n","Answers to the questions below will be found [here](https://github.com/PennNGG/Quantitative-Neuroscience/tree/master/Answers%20to%20Exercises/Python) after the due date."]},{"cell_type":"markdown","metadata":{"id":"zIfgeegzTlJl"},"source":["##### 1\\. Plot X vs Y. Do they look related?"]},{"cell_type":"markdown","metadata":{"id":"v4ihoOv0TzTk"},"source":["##### 2\\. Calculate $r_{X,Y}$ and $r_{Y,X}$, first using the equations above and then using either the Python numpy funciton [corrcoef](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html) or Matlab's built-in [corrcoef](https://www.mathworks.com/help/matlab/ref/corrcoef.html). Did you get the same answers?"]},{"cell_type":"markdown","metadata":{"id":"XqoZSFdZU5zg"},"source":["##### 3\\. What is the standard error of $r_{X,Y}$? The 95% confidence intervals computed from the standard error?"]},{"cell_type":"markdown","metadata":{"id":"sU0UjR6uVMl2"},"source":["##### 4\\. Should the value of $r_{X,Y}$ be considered significant at the *p*<0.05 level, given a two-tailed test (i.e., we reject if the test statistic is too large on either tail of the null distribution) for $H_0: r_{X,Y}=0$?"]},{"cell_type":"markdown","metadata":{"id":"mywqPzz3Vg0I"},"source":["##### 5\\. Yale does the exact same study and finds that his correlation value is 0.75. Is this the same as yours? That is, evaluate $ùêª_0: r=0.75$."]},{"cell_type":"markdown","metadata":{"id":"qYW4bBQ7Vxa-"},"source":["##### 6\\. Finally, calculate the statistical power and sample size needed to reject $H_0:r=0\\:when\\:r\\ge 0.5$."]},{"cell_type":"markdown","metadata":{"id":"UqoNXyuxP-go"},"source":["# Additional Resources\n"]},{"cell_type":"markdown","metadata":{"id":"clnBO4FU28El"},"source":["- Differences between correlation and regression are discussed [here](https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/11-correlation-and-regression) and [here](http://www.biostathandbook.com/linearregression.html).\n","\n","- A reference on [how to choose the appropriate measure of association](https://journals.sagepub.com/doi/pdf/10.1177/8756479308317006) (Khamis 2008)."]},{"cell_type":"markdown","metadata":{"id":"tteEm2Qlgbb3"},"source":["# Credits\n","\n","Copyright 2021 by Joshua I. Gold, University of Pennsylvania"]}],"metadata":{"colab":{"collapsed_sections":["IyCyVIIDH0rb","xDpz-ktIJGhf","ELEb_vqYQGdK","NUeNn8deHBch","nvmWeSSHSF95","zIfgeegzTlJl","v4ihoOv0TzTk","XqoZSFdZU5zg","sU0UjR6uVMl2","mywqPzz3Vg0I","qYW4bBQ7Vxa-"],"name":"Parametric Correlation Coefficient","provenance":[{"file_id":"1dvkIh9KgmzwwJ7phFBxkHmS3nFTKN_yo","timestamp":1626368223618},{"file_id":"1AmfvDhhfviRQFvONiUVUba_6hof8RDp6","timestamp":1626367834690},{"file_id":"1wTKRgKK5eDUya7FZRHeu1RaoY7kuhiGi","timestamp":1626364730636},{"file_id":"1rdJMusMZDTaM9OGsyt27tCVkSasmRj2O","timestamp":1626357708093},{"file_id":"1HW0L_d5Wpod3jbnY3iG7mLhMG6yWHvF2","timestamp":1626350171621},{"file_id":"1-KxH3FCq5rDyyO33HXxewIv-kKldkINi","timestamp":1626290714843},{"file_id":"14S2ca44h8TKC1hFXjk5ktwBYpGU6R5S-","timestamp":1624411796822}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
